{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7e77a34",
   "metadata": {},
   "source": [
    "# Homework\n",
    "- **due Wed Sep 3 at 3 pm JST**\n",
    "- if you had trouble setting up our `hsi25_ml-ssc_25.0` conda environment, please install `matminer` separately to complete this HW\n",
    "- you can install this in a code cell at the top of your notebook using the line: `!pip install matminer` (simply remove the `#` from the following cell and execute it). This may take a few minutes. If you run into issues, you can find more installation instructions at this link: https://hackingmaterials.lbl.gov/matminer/installation.html\n",
    "- please feel free to email Prof. Bartel (`cbartel@umn.edu`) if you have questions related to the assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e951563a-d16f-4fbd-8e0a-7d596a2e21ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install matminer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaa84e5",
   "metadata": {},
   "source": [
    "# Scoring\n",
    "- (1) = 50 points\n",
    "    - (a): 8 points\n",
    "    - (b): 20 points\n",
    "    - (c): 10 points\n",
    "    - (d): 12 points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1792d587",
   "metadata": {},
   "source": [
    "# (1) Consider this paper:\n",
    "Machine Learning Directed Search for Ultraincompressible, Superhard Materials \\\n",
    "Aria Mansouri Tehrani, Anton O. Oliynyk, Marcus Parry, Zeshan Rizvi, Samantha Couper, Feng Lin, Lowell Miyagi, Taylor D. Sparks, and Jakoah Brgoch* \n",
    "\n",
    "J. Am. Chem. Soc. 2018, 140, 31, 9844â€“9853"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888ce80f",
   "metadata": {},
   "source": [
    "## (a) Understanding what they did\n",
    "**Guidelines**:\n",
    "- Answer each of the following in 1-3 sentences\n",
    "- Use markdown cells for your answers\n",
    "### (1) What was the objective of this paper?\n",
    "### (2) Was this supervised or unsupervised learning?\n",
    "### (3) Was this regression or classification?\n",
    "### (4) Describe their approach to validating their machine learning model.\n",
    "\n",
    "**Scoring**:\n",
    "- +1 point for attempting each\n",
    "- +1 point for suitable answer to each"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068264c5",
   "metadata": {},
   "source": [
    "### Students answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc60e38f",
   "metadata": {},
   "source": [
    "## Exploring their data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2e924e",
   "metadata": {},
   "source": [
    "### Load their data using matminer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2421214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matminer.datasets import load_dataset\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "df = load_dataset('brgoch_superhard_training')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef41fe5",
   "metadata": {},
   "source": [
    "### Convert their feature dicts to columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c5445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "brgoch_feat_dicts = df['brgoch_feats'].values\n",
    "brgoch_feat_names = sorted(list(brgoch_feat_dicts[0].keys()))\n",
    "\n",
    "for feature in brgoch_feat_names:\n",
    "    df[feature] = [feat_dict[feature] for feat_dict in brgoch_feat_dicts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fd93ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716ed5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1eaf4b",
   "metadata": {},
   "source": [
    "### Separate features from targets and non-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e56504",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['bulk_modulus', 'shear_modulus']\n",
    "non_features = ['formula', 'composition', 'material_id', 'structure', 'brgoch_feats', 'suspect_value']\n",
    "columns = list(df)\n",
    "features = [f for f in columns if f not in targets if f not in non_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9da58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2101313a",
   "metadata": {},
   "source": [
    "## (b) Train a support vector regressor to predict bulk modulus\n",
    "**Guidelines**:\n",
    "1. reserve 15% of your data for testing\n",
    "2. scale your features \n",
    "3. identify the best regularization parameter (`C`) to use with a polynomial kernel\n",
    "4. plot the training and validation RMSE as a function of `C` and breifly discuss why you think the `C` value you chose is best (1-2 sentences)\n",
    "\n",
    "**Scoring**:\n",
    "- +2 points for attempting each point in the guidelines\n",
    "- +3 points for satisfactorily addressing each point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882ddb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Students answer here (and in more cells below)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64d004c-6c9e-480e-ade5-756bbc52c37a",
   "metadata": {},
   "source": [
    "### Students comment on your solution here (justify your selection of C)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf63ae8",
   "metadata": {},
   "source": [
    "### (c) Use permutation importances to determine which features are most important for this prediction\n",
    "\n",
    "**Guidelines**:\n",
    "- use `sklearn.inspection.permutation_importance`\n",
    "- use `SVR(kernel='poly', C=32)` as your estimator\n",
    "- permutation importances should be determined on a validation set\n",
    "    - you should fit your estimator to a subset of `X_train`, `y_train` and determine importances using a different subset\n",
    "- use `n_repeats = 2` so that it doesn't take too long\n",
    "- use `scoring = 'neg_root_mean_squared_error'`\n",
    "- print the 10 most important features\n",
    "    - print the feature name along with the importance value\n",
    "- plot a bar chart of all sorted importances\n",
    "    - the y-axis is the feature importance\n",
    "    - the x-axis is the index of each feature (index = 0 should correspond with the most important feature)\n",
    "\n",
    "**Hints**:\n",
    "- review the [User Guide](https://scikit-learn.org/stable/modules/permutation_importance.html#permutation-importance) for `permutation_importance`\n",
    "\n",
    "**Scoring**:\n",
    "- +4 points for attempting\n",
    "- +3 points for successfully computing permutation importances\n",
    "- +1 point for correctly using a validation set\n",
    "- +1 point for printing the 10 most important features and their corresponding importance values\n",
    "- +1 point for generating the bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4219211",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Students answer here (and in below cells)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25d4c17-0d85-4533-9f48-9c1ec51f607f",
   "metadata": {},
   "source": [
    "### (d) Consider how feature correlations might influence your results\n",
    "**Guidelines**:\n",
    "- compute the pairwise Pearson correlation among three features in your model: `['crystal_radius_feat_1', 'covalent_radius_feat_1', 'ionic_radius_feat_1']`\n",
    "- for the purposes of this exercise, it's OK to use your full data (ie the whole DataFrame). In practice, you'd want to do this only on the training set\n",
    "- your printed output should be:\n",
    "  - PC(feature 1, feature 2) = <the Pearson correlation between feature 1 and feature 2> \n",
    "  - PC(feature 1, feature 3) = <the Pearson correlation between feature 1 and feature 3>\n",
    "  - PC(feature 2, feature 3) = <the Pearson correlation between feature 2 and feature 3>\n",
    "- discuss the implications of these correlations on: 1) training the model and 2) interpreting the feature importances\n",
    "\n",
    "**Hints**:\n",
    "- [this link](https://realpython.com/numpy-scipy-pandas-correlation-python/) may help\n",
    "\n",
    "**Scoring**:\n",
    "- +4 points for attempting\n",
    "- +4 points for correctly computing and printing Pearson correlations\n",
    "- +2 points for discussing implications for training\n",
    "- +2 points for appropriately discussing implications for interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ac76a1-ba32-4ce4-9ad5-cd18e9b35279",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Students answer here (and in below cells)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f98c89-1c6e-4339-afee-812490cf3438",
   "metadata": {},
   "source": [
    "### Students comment on your solution here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsi25_ml-ssc_25.0",
   "language": "python",
   "name": "hsi25_ml-ssc_25.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
