{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecb5e64c-9937-4ccc-8c9c-f8b4cd0241cb",
   "metadata": {},
   "source": [
    "# Objectives of this Lab\n",
    "- understand the role of material \"representations\"\n",
    "\n",
    "## Reminders\n",
    "- activate your hsi25_ml-ssc_25.0 conda env (kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08119604-226e-4a1a-a00f-4b82bba1744c",
   "metadata": {},
   "source": [
    "# This time\n",
    "- representing complex data (primarily molecules and materials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2850168e-1e06-40d7-a9b5-36f4b9713be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "plt.style.use('../files/plot_style.mplstyle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbb6e80-ea77-4bcd-af3a-8d40ae0e114a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymatgen.core.structure import Structure\n",
    "from pymatgen.core.composition import Composition\n",
    "\n",
    "from matminer.datasets import load_dataset\n",
    "from matminer.featurizers.composition.composite import ElementProperty\n",
    "from matminer.featurizers.composition.element import ElementFraction\n",
    "from matminer.featurizers.structure.rdf import RadialDistributionFunction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e550c534-5ff5-4dd1-8ef1-004290f38a37",
   "metadata": {},
   "source": [
    "# Representing crystal structures\n",
    "- let's take a look at the \"FLLA\" dataset --> F. Faber, A. Lindmaa, O.A. von Lilienfeld, R. Armiento, “Crystal structure representations for machine learning models of formation energies”, Int. J. Quantum Chem. 115 (2015) 1094–1101. doi:10.1002/qua.24917\n",
    "- ~4000 inorganic materials\n",
    "- ground-truth is plane wave density functional theory\n",
    "- goal is for our ML model to be a surrogate for DFT by giving us a fast estimate of the formation energy (used as input to thermodynamic models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96a83d7-38c2-4315-bc5e-a4e62552c21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset('flla')\n",
    "del df['formula']\n",
    "\n",
    "def get_formula(row):\n",
    "    s = row['structure']\n",
    "    formula = s.formula\n",
    "    reduced_formula = Composition(formula).reduced_formula\n",
    "    return reduced_formula\n",
    "\n",
    "df['formula'] = df.apply(get_formula, axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914a47fe-cbe9-4b0b-a5df-54a501f98bd5",
   "metadata": {},
   "source": [
    "# First, we'll get a fingerprint that just captures the chemical composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87e90a2-677f-46a7-bdf0-473f9d01e2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elfrac_composition_vector(row):\n",
    "    return ElementFraction().featurize(Composition(row['formula']))\n",
    "\n",
    "df['elfrac_vector'] = df.apply(get_elfrac_composition_vector, axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192dc34d-6ab5-40cc-8b51-77ac050eea81",
   "metadata": {},
   "outputs": [],
   "source": [
    "LiCl_elfrac = df.elfrac_vector.get(df.formula == 'LiCl').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bfa9a0-6cf9-49e6-a348-1ee8b33ba2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "LiCl_elfrac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54ea31f-89a1-4fdf-869e-99c32ab70846",
   "metadata": {},
   "source": [
    "# Now, we'll get a fingerprint that captures elemental **properties**\n",
    "- converting chemical formulas into vectors using things like average electronegativity, average radius, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267f3e25-e8b5-4d13-8c95-c8cc147d0d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "elprop = ElementProperty.from_preset('matminer')\n",
    "elprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df744f68-62fc-4017-b3e9-2ad73e81f2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_props = ElementProperty(data_source='pymatgen', features=['X', 'mendeleev_no', 'atomic_radius', 'melting_point'], stats=['mean', 'std_dev'])\n",
    "our_props"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d310231-af1a-4163-9c56-d30202d83017",
   "metadata": {},
   "source": [
    "## Let's look at a random formula in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0965f38a-c008-4730-9427-90011c3a2b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_formula = df.formula.values[21]\n",
    "print(some_formula)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031dfcd7-205d-4b79-97d6-611e8ebc88f7",
   "metadata": {},
   "source": [
    "## Now convert that formula to our \"element property\" vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e458b0fc-55f2-451f-8d73-09d6d820a290",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_props.featurize(Composition(some_formula))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4556bfb6-63c6-42ed-89df-036b9d277088",
   "metadata": {},
   "source": [
    "## What do those values correspond with?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32be676f-1630-4238-b336-c2fe194535cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_and_values(formula):\n",
    "    feature_values = our_props.featurize(Composition(formula))\n",
    "    feature_labels = our_props.feature_labels()\n",
    "    labels_to_values = dict(zip(feature_labels, feature_values))\n",
    "    labels_to_values = {k.strip('PymatgenData').replace(' ', '_')[1:] : v for i, (k, v) in enumerate(labels_to_values.items()) if v}\n",
    "    return labels_to_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d593f73b-4da8-4934-8fc7-12f0da3fdb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_features_and_values(some_formula)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e290d318-5cf1-46ca-9716-4e02bc111342",
   "metadata": {},
   "source": [
    "## Let's apply this to our whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db13f66e-4d1a-41b8-93fb-7f06b92b65ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matminer_composition_vector(row):    \n",
    "    elprop = our_props\n",
    "    formula = row['formula']\n",
    "    return elprop.featurize(Composition(formula))\n",
    "\n",
    "df['matminer_vector'] = df.apply(get_matminer_composition_vector, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10015d0d-ba11-409d-bbed-dfb4a7a86670",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ec48f3-c44e-47f9-8853-66105a582387",
   "metadata": {},
   "source": [
    "# Let's compare the two fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60c2abd-d07d-4718-8cb4-f13b667623c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'NaMnSe2'\n",
    "\n",
    "elfrac_vector = df['elfrac_vector'].get(df.formula == formula).values[0]\n",
    "matminer_vector = df['matminer_vector'].get(df.formula == formula).values[0]\n",
    "\n",
    "print('elfrac_vector has %i features' % len(elfrac_vector))\n",
    "print('matminer_vector has %i features' % len(matminer_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b82736-0533-42ab-954c-aed0428b9cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = plt.subplot(211)\n",
    "ax1 = plt.bar(list(range(len(elfrac_vector))), elfrac_vector)\n",
    "ax2 = plt.subplot(212)\n",
    "ax2 = plt.bar(list(range(len(matminer_vector))), matminer_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db34197-e33f-4296-bf84-644505ed665a",
   "metadata": {},
   "source": [
    "# Now we could train models with each. Which one do you think should work better?\n",
    "- we'll write a quick function to run CV with these models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e79e92f-4c51-465f-b224-21bb9c46c082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV(feature):\n",
    "    # convert our single column containing all features into a feature matrix (each item of the vector becomes a column of the matrix)\n",
    "    X = np.vstack(df[feature].values)\n",
    "\n",
    "    # grab our target\n",
    "    y = df['formation_energy_per_atom'].values\n",
    "\n",
    "    # split our data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=44)\n",
    "\n",
    "    # use mean imputation (to fill in NaNs)\n",
    "    imputer = SimpleImputer(strategy='mean')    \n",
    "\n",
    "    # initialize a vanilla random forest\n",
    "    rf = RandomForestRegressor()\n",
    "\n",
    "    # impute --> fit\n",
    "    pipe = Pipeline([('impute', imputer), ('rf', rf)])\n",
    "\n",
    "    # run three-fold CV\n",
    "    scores = cross_validate(pipe, X_train, y_train, cv=3, return_train_score=True, scoring='neg_root_mean_squared_error')\n",
    "    print('Training score = %.3f +/- %.4f' % (np.mean(abs(scores['train_score'])), np.std(abs(scores['train_score']))))\n",
    "    print('Validation score = %.3f +/- %.4f' % (np.mean(abs(scores['test_score'])), np.std(abs(scores['test_score']))))\n",
    "\n",
    "    # re-train model on full training set (to inspect importances)\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    # return scores and the model fit to the full training set\n",
    "    return scores, pipe['rf']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e515170b-f9da-429a-a32f-abcae997e471",
   "metadata": {},
   "source": [
    "# Now, we'll compare the featurization based on element fraction and based on the element properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bffd864-3251-403c-9ab4-66fba1f5cbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in ['elfrac_vector', 'matminer_vector']:\n",
    "    print('~~~~ %s ~~~~' % feature)\n",
    "    scores, rf = CV(feature)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e71ddea-c6e4-461d-ac46-237528b6dc29",
   "metadata": {},
   "source": [
    "### With ~10x fewer features, the element property (matminer vector) does better!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b181cef9-a7e2-4504-9ee1-e9f2137827ce",
   "metadata": {},
   "source": [
    "# Let's see which features are most important\n",
    "- the default built-in `feature_importances_` applies average impurity decrease to rank feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82ee2d6-7e70-443b-84c5-45138466fe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eea9b45-11b9-447b-aff6-4faa35309d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importances(features_and_their_importances, ylabel='average impurity decrease', n_features_to_plot=10, figsize=(7,5)):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        features_and_their_importances (dict):\n",
    "            {feature (str) : importance (float)}\n",
    "    Returns:\n",
    "        matplotlib bar chart of sorted importances\n",
    "    \"\"\"\n",
    "    axis_width = 1.5\n",
    "    maj_tick_len = 6\n",
    "    fontsize = 14\n",
    "    bar_color = 'lightblue'\n",
    "    align = 'center'\n",
    "    label = '__nolegend__'\n",
    "    \n",
    "    sorted_features = sorted(features_and_their_importances, \n",
    "                             key=features_and_their_importances.get, \n",
    "                             reverse=True)\n",
    "    sorted_importances = [features_and_their_importances[f] for f in sorted_features]\n",
    "\n",
    "    if len(sorted_features) < n_features_to_plot:\n",
    "        n_features_to_plot = len(sorted_features)\n",
    "\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = plt.bar(range(n_features_to_plot), sorted_importances[:n_features_to_plot],\n",
    "                 color=bar_color, align=align, label=label)\n",
    "    ax = plt.xticks(range(n_features_to_plot), sorted_features[:n_features_to_plot], rotation=90)\n",
    "    ax = plt.xlim([-1, n_features_to_plot])\n",
    "    ax = plt.ylabel(ylabel, fontsize=fontsize)\n",
    "    ax = plt.tick_params('both', length=maj_tick_len, width=axis_width, \n",
    "                         which='major', right=True, top=True)\n",
    "    ax = plt.xticks(fontsize=fontsize)\n",
    "    ax = plt.yticks(fontsize=fontsize)\n",
    "    ax = plt.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b087d5-4a6a-41b3-976d-73d22c94e637",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_labels = list(get_features_and_values(formula).keys())\n",
    "features_and_their_importances = dict(zip(feature_labels, importances))\n",
    "plot_importances(features_and_their_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6db834c-d59a-49a8-9e23-0a3492338e54",
   "metadata": {},
   "source": [
    "## Let's compare to the element fraction features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cacbbff-d69a-4479-9e1f-0f5dd80ee9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, rf = CV('elfrac_vector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a176850b-6601-4064-a941-5b91ca75ab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "feature_labels = ElementFraction().feature_labels()\n",
    "features_and_their_importances = dict(zip(feature_labels, importances))\n",
    "plot_importances(features_and_their_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6226e5-59e0-4506-88ed-2a4d0c334ead",
   "metadata": {},
   "source": [
    "# How does this compare to published models for formation energy?\n",
    "- Here is the state of the art for a similar prediction task using only chemical composition (from [this paper](https://www.nature.com/articles/s41467-020-19964-7))\n",
    "![](../files/roost.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a78560-6025-4c5e-a71e-77aefc3e36b3",
   "metadata": {},
   "source": [
    "## What if we also know the crystal structure?\n",
    "- from [this paper](https://www.nature.com/articles/s41586-023-06735-9)\n",
    "\n",
    "![](../files/gnome.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65cf569-ba9e-4592-8a88-95443cb382bf",
   "metadata": {},
   "source": [
    "# Let's look at a crystal structure file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81aeb20-6d28-426c-affd-6fed0ee009a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = 3935\n",
    "\n",
    "structure = df['structure'].values[random_index]\n",
    "\n",
    "print(structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf98395-cd5b-416c-a9a7-57e96a9fbebb",
   "metadata": {},
   "source": [
    "# Featurizing crystal structures introduces new challenges:\n",
    "- how do we create \"fixed-length\" vectors to feed to ML models?\n",
    "- how do we handle \"invariances\" (eg wrt to supercell expansions)?\n",
    "- how do we encode chemical identities in addition to atomic positions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a300913-7257-453c-903b-63665797a1ef",
   "metadata": {},
   "source": [
    "# Let's explore one approach to featurizing structure\n",
    "- the radial distribution function\n",
    "- here, our features will simply be a binned histogram of distances (r) and the values for each feature will be g(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6afc389-c2cd-4ff7-b216-a6621048d7f5",
   "metadata": {},
   "source": [
    "## This will nicely handle \"fixed-length\" problem and supercell invariances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256c6b4a-187f-4877-b8b2-0a6ab023f2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = RadialDistributionFunction()\n",
    "unitcell = df.structure.get(df.formula == 'AlN').values[0]\n",
    "supercell = unitcell.make_supercell(2,2,2)\n",
    "\n",
    "unit_rdf = rdf.featurize(unitcell)\n",
    "super_rdf = rdf.featurize(supercell)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(211)\n",
    "ax = plt.bar(list(range(len(unit_rdf))), unit_rdf)\n",
    "ax = plt.subplot(212)\n",
    "ax = plt.bar(list(range(len(super_rdf))), super_rdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90e9a01-86c4-494c-87b4-d0b2da328f41",
   "metadata": {},
   "source": [
    "## Let's compare our three \"fingerprints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a778b4-7860-4da8-bcf8-5e77209931c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'NaMnSe2'\n",
    "elfrac_vector = df['elfrac_vector'].get(df.formula == formula).values[0]\n",
    "matminer_vector = df['matminer_vector'].get(df.formula == formula).values[0]\n",
    "rdf_vector = rdf.featurize(df['structure'].get(df.formula == formula).values[0])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = plt.subplot(311)\n",
    "ax1 = plt.bar(list(range(len(elfrac_vector))), elfrac_vector)\n",
    "ax2 = plt.subplot(312)\n",
    "ax2 = plt.bar(list(range(len(matminer_vector))), matminer_vector)\n",
    "ax3 = plt.subplot(313)\n",
    "ax3 = plt.bar(list(range(len(rdf_vector))), rdf_vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd331d2-d83c-431a-9fac-a40872101c22",
   "metadata": {},
   "source": [
    "## Let's apply the rdf vector to all materials (this may take a minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646a0083-6f63-4a2d-873d-3b1591c6170c",
   "metadata": {},
   "outputs": [],
   "source": [
    "structures = df.structure.values\n",
    "rdfs = [rdf.featurize(s) for s in structures]\n",
    "df['rdf_vector'] = rdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e94da87-281d-49b7-bbf6-8e4061f7f65f",
   "metadata": {},
   "source": [
    "# A common way to understand representations is through \"similarities\"\n",
    "- cosine similarity --> popular for high-dimensional representations (vectors)\n",
    "- Euclidean similarity --> more amenable to low-dimensional representations (common \"distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19063123-4f3c-4cf9-b6ad-1ad16efc766d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(a, b, method='cosine'):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        a (np.array) : a feature vector for a material\n",
    "        b (np.array) : a feature vector for another material\n",
    "        method (str) : \"cosine\" or \"euclidean\"\n",
    "\n",
    "    Returns:\n",
    "        if method == 'cosine':\n",
    "            the cosine similarity (1 - the cosine distance between the two vectors) (float)\n",
    "        if method == 'euclidean':\n",
    "            the inverse Euclidean distance (float)\n",
    "    \"\"\"    \n",
    "    a = np.nan_to_num(a)\n",
    "    b = np.nan_to_num(b)\n",
    "    if method == 'cosine':\n",
    "        return np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "    elif method == 'euclidean':\n",
    "        dist = np.linalg.norm(a-b)\n",
    "        if dist != 0:\n",
    "            return 1/dist\n",
    "        else:\n",
    "            return 1e6\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6e7c9e-a998-4cd3-91a4-eb76b4ea0147",
   "metadata": {},
   "source": [
    "## Group activities\n",
    "**Guidelines**\n",
    "- Find the 5 materials in your dataset that are most similar to aluminum nitride (AlN).\n",
    "- Consider the choice of representation. Does it matter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99534427-1192-4f8f-9841-6a688b3f4b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### STUDENTS CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce54b96f-53a1-4981-8edd-33ccc35237ff",
   "metadata": {},
   "source": [
    "## Let's fit some models using the rdf vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80bd65c-89d2-49a3-816e-2b734125432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, rf = CV('rdf_vector')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0f0778-156f-456d-8da9-ba1105644730",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "feature_labels = list(range(len(importances)))\n",
    "features_and_their_importances = dict(zip(feature_labels, importances))\n",
    "plot_importances(features_and_their_importances, n_features_to_plot=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db37e655-212f-4e3d-a820-a43b9d7f6469",
   "metadata": {},
   "source": [
    "# More processing (and probably data!) required.. and algorithm matters! \n",
    "- Kernel ridge regression is popular with these fingerprint-like features\n",
    "  - read more about KRR [here](https://dmol.pub/ml/kernel.html) and [here](https://github.com/fullmetalfelix/ML-CSC-tutorial/blob/master/krr_homo.ipynb) (among many other places)\n",
    "- also more approaches that are especially amenable to kernel-based methods (e.g., see [SOAP](https://singroup.github.io/dscribe/0.3.x/tutorials/soap.html)) and many more that are amenable to deep learning (e.g., [equivariant neural networks](https://github.com/mir-group/nequip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0202c4-0ae6-43ea-839f-59b2183e7c57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsi25_ml-ssc_25.0",
   "language": "python",
   "name": "hsi25_ml-ssc_25.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
