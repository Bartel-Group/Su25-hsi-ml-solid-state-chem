{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7e77a34",
   "metadata": {},
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaa84e5",
   "metadata": {},
   "source": [
    "# Scoring\n",
    "- (1) = 50 points\n",
    "    - (a): 8 points\n",
    "    - (b): 20 points\n",
    "    - (c): 10 points\n",
    "    - (d): 12 points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1792d587",
   "metadata": {},
   "source": [
    "# (1) Consider this paper:\n",
    "Machine Learning Directed Search for Ultraincompressible, Superhard Materials \\\n",
    "Aria Mansouri Tehrani, Anton O. Oliynyk, Marcus Parry, Zeshan Rizvi, Samantha Couper, Feng Lin, Lowell Miyagi, Taylor D. Sparks, and Jakoah Brgoch* \n",
    "\n",
    "J. Am. Chem. Soc. 2018, 140, 31, 9844â€“9853"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888ce80f",
   "metadata": {},
   "source": [
    "## (a) Understanding what they did\n",
    "**Guidelines**:\n",
    "- Answer each of the following in 1-3 sentences\n",
    "- Use markdown cells for your answers\n",
    "### (1) What was the objective of this paper?\n",
    "### (2) Was this supervised or unsupervised learning?\n",
    "### (3) Was this regression or classification?\n",
    "### (4) Describe their approach to validating their machine learning model.\n",
    "\n",
    "**Scoring**:\n",
    "- +1 point for attempting each\n",
    "- +1 point for suitable answer to each"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068264c5",
   "metadata": {},
   "source": [
    "### SOLUTION\n",
    "\n",
    "- (1): discover new inorganic materials with high hardness\n",
    "- (2): supervised (they have labeled data)\n",
    "- (3): regression (the quantities they predict are continuous)\n",
    "- (4): they used 20-fold CV for feature selection, then 10-fold CV to estimate generalization with features fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc60e38f",
   "metadata": {},
   "source": [
    "## Exploring their data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2e924e",
   "metadata": {},
   "source": [
    "### Load their data using matminer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2421214d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formula</th>\n",
       "      <th>bulk_modulus</th>\n",
       "      <th>shear_modulus</th>\n",
       "      <th>composition</th>\n",
       "      <th>material_id</th>\n",
       "      <th>structure</th>\n",
       "      <th>brgoch_feats</th>\n",
       "      <th>suspect_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AlPt3</td>\n",
       "      <td>225.230461</td>\n",
       "      <td>91.197748</td>\n",
       "      <td>(Al, Pt)</td>\n",
       "      <td>mp-188</td>\n",
       "      <td>[[0. 0. 0.] Al, [0.         1.96140395 1.96140...</td>\n",
       "      <td>{'atomic_number_feat_1': 123.5, 'atomic_number...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mn2Nb</td>\n",
       "      <td>232.696340</td>\n",
       "      <td>74.590157</td>\n",
       "      <td>(Mn, Nb)</td>\n",
       "      <td>mp-12659</td>\n",
       "      <td>[[-2.23765223e-08  1.42974191e+00  5.92614104e...</td>\n",
       "      <td>{'atomic_number_feat_1': 45.5, 'atomic_number_...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HfO2</td>\n",
       "      <td>204.573433</td>\n",
       "      <td>98.564374</td>\n",
       "      <td>(Hf, O)</td>\n",
       "      <td>mp-352</td>\n",
       "      <td>[[2.24450185 3.85793022 4.83390736] O, [2.7788...</td>\n",
       "      <td>{'atomic_number_feat_1': 44.0, 'atomic_number_...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cu3Pt</td>\n",
       "      <td>159.312640</td>\n",
       "      <td>51.778816</td>\n",
       "      <td>(Cu, Pt)</td>\n",
       "      <td>mp-12086</td>\n",
       "      <td>[[0.         1.86144248 1.86144248] Cu, [1.861...</td>\n",
       "      <td>{'atomic_number_feat_1': 82.5, 'atomic_number_...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mg3Pt</td>\n",
       "      <td>69.637565</td>\n",
       "      <td>27.588765</td>\n",
       "      <td>(Mg, Pt)</td>\n",
       "      <td>mp-18707</td>\n",
       "      <td>[[0.         0.         2.73626461] Mg, [0.   ...</td>\n",
       "      <td>{'atomic_number_feat_1': 57.0, 'atomic_number_...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  formula  bulk_modulus  shear_modulus composition material_id  \\\n",
       "0   AlPt3    225.230461      91.197748    (Al, Pt)      mp-188   \n",
       "1   Mn2Nb    232.696340      74.590157    (Mn, Nb)    mp-12659   \n",
       "2    HfO2    204.573433      98.564374     (Hf, O)      mp-352   \n",
       "3   Cu3Pt    159.312640      51.778816    (Cu, Pt)    mp-12086   \n",
       "4   Mg3Pt     69.637565      27.588765    (Mg, Pt)    mp-18707   \n",
       "\n",
       "                                           structure  \\\n",
       "0  [[0. 0. 0.] Al, [0.         1.96140395 1.96140...   \n",
       "1  [[-2.23765223e-08  1.42974191e+00  5.92614104e...   \n",
       "2  [[2.24450185 3.85793022 4.83390736] O, [2.7788...   \n",
       "3  [[0.         1.86144248 1.86144248] Cu, [1.861...   \n",
       "4  [[0.         0.         2.73626461] Mg, [0.   ...   \n",
       "\n",
       "                                        brgoch_feats  suspect_value  \n",
       "0  {'atomic_number_feat_1': 123.5, 'atomic_number...          False  \n",
       "1  {'atomic_number_feat_1': 45.5, 'atomic_number_...          False  \n",
       "2  {'atomic_number_feat_1': 44.0, 'atomic_number_...          False  \n",
       "3  {'atomic_number_feat_1': 82.5, 'atomic_number_...          False  \n",
       "4  {'atomic_number_feat_1': 57.0, 'atomic_number_...          False  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matminer.datasets import load_dataset\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "df = load_dataset('brgoch_superhard_training')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef41fe5",
   "metadata": {},
   "source": [
    "### Convert their feature dicts to columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7c5445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "brgoch_feat_dicts = df['brgoch_feats'].values\n",
    "brgoch_feat_names = sorted(list(brgoch_feat_dicts[0].keys()))\n",
    "\n",
    "for feature in brgoch_feat_names:\n",
    "    df[feature] = [feat_dict[feature] for feat_dict in brgoch_feat_dicts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69fd93ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formula</th>\n",
       "      <th>bulk_modulus</th>\n",
       "      <th>shear_modulus</th>\n",
       "      <th>composition</th>\n",
       "      <th>material_id</th>\n",
       "      <th>structure</th>\n",
       "      <th>brgoch_feats</th>\n",
       "      <th>suspect_value</th>\n",
       "      <th>Allred-Rochow_EN_feat_1</th>\n",
       "      <th>Allred-Rochow_EN_feat_2</th>\n",
       "      <th>...</th>\n",
       "      <th>specific_heat_feat_1</th>\n",
       "      <th>specific_heat_feat_2</th>\n",
       "      <th>specific_heat_feat_3</th>\n",
       "      <th>specific_heat_feat_4</th>\n",
       "      <th>thermal_conductivity_feat_1</th>\n",
       "      <th>thermal_conductivity_feat_2</th>\n",
       "      <th>thermal_conductivity_feat_3</th>\n",
       "      <th>thermal_conductivity_feat_4</th>\n",
       "      <th>valence_electron_density</th>\n",
       "      <th>volume_per_atom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AlPt3</td>\n",
       "      <td>225.230461</td>\n",
       "      <td>91.197748</td>\n",
       "      <td>(Al, Pt)</td>\n",
       "      <td>mp-188</td>\n",
       "      <td>[[0. 0. 0.] Al, [0.         1.96140395 1.96140...</td>\n",
       "      <td>{'atomic_number_feat_1': 123.5, 'atomic_number...</td>\n",
       "      <td>False</td>\n",
       "      <td>3.3865</td>\n",
       "      <td>3.547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.90</td>\n",
       "      <td>225.90000</td>\n",
       "      <td>22.20000</td>\n",
       "      <td>71.60000</td>\n",
       "      <td>237.0</td>\n",
       "      <td>0.899196</td>\n",
       "      <td>14.457360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mn2Nb</td>\n",
       "      <td>232.696340</td>\n",
       "      <td>74.590157</td>\n",
       "      <td>(Mn, Nb)</td>\n",
       "      <td>mp-12659</td>\n",
       "      <td>[[-2.23765223e-08  1.42974191e+00  5.92614104e...</td>\n",
       "      <td>{'atomic_number_feat_1': 45.5, 'atomic_number_...</td>\n",
       "      <td>False</td>\n",
       "      <td>2.4550</td>\n",
       "      <td>2.090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.48</td>\n",
       "      <td>34.67000</td>\n",
       "      <td>38.06000</td>\n",
       "      <td>7.82000</td>\n",
       "      <td>53.7</td>\n",
       "      <td>0.947211</td>\n",
       "      <td>12.668777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HfO2</td>\n",
       "      <td>204.573433</td>\n",
       "      <td>98.564374</td>\n",
       "      <td>(Hf, O)</td>\n",
       "      <td>mp-352</td>\n",
       "      <td>[[2.24450185 3.85793022 4.83390736] O, [2.7788...</td>\n",
       "      <td>{'atomic_number_feat_1': 44.0, 'atomic_number_...</td>\n",
       "      <td>False</td>\n",
       "      <td>4.1900</td>\n",
       "      <td>6.060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.990</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.92</td>\n",
       "      <td>11.52674</td>\n",
       "      <td>22.94652</td>\n",
       "      <td>0.02674</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.850563</td>\n",
       "      <td>11.756914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cu3Pt</td>\n",
       "      <td>159.312640</td>\n",
       "      <td>51.778816</td>\n",
       "      <td>(Cu, Pt)</td>\n",
       "      <td>mp-12086</td>\n",
       "      <td>[[0.         1.86144248 1.86144248] Cu, [1.861...</td>\n",
       "      <td>{'atomic_number_feat_1': 82.5, 'atomic_number_...</td>\n",
       "      <td>False</td>\n",
       "      <td>3.6350</td>\n",
       "      <td>3.830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.635</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.38</td>\n",
       "      <td>637.30000</td>\n",
       "      <td>1131.40000</td>\n",
       "      <td>71.60000</td>\n",
       "      <td>401.0</td>\n",
       "      <td>1.740288</td>\n",
       "      <td>12.066970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mg3Pt</td>\n",
       "      <td>69.637565</td>\n",
       "      <td>27.588765</td>\n",
       "      <td>(Mg, Pt)</td>\n",
       "      <td>mp-18707</td>\n",
       "      <td>[[0.         0.         2.73626461] Mg, [0.   ...</td>\n",
       "      <td>{'atomic_number_feat_1': 57.0, 'atomic_number_...</td>\n",
       "      <td>False</td>\n",
       "      <td>2.7995</td>\n",
       "      <td>2.159</td>\n",
       "      <td>...</td>\n",
       "      <td>1.595</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.02</td>\n",
       "      <td>269.80000</td>\n",
       "      <td>396.40000</td>\n",
       "      <td>71.60000</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.638524</td>\n",
       "      <td>18.793352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  formula  bulk_modulus  shear_modulus composition material_id  \\\n",
       "0   AlPt3    225.230461      91.197748    (Al, Pt)      mp-188   \n",
       "1   Mn2Nb    232.696340      74.590157    (Mn, Nb)    mp-12659   \n",
       "2    HfO2    204.573433      98.564374     (Hf, O)      mp-352   \n",
       "3   Cu3Pt    159.312640      51.778816    (Cu, Pt)    mp-12086   \n",
       "4   Mg3Pt     69.637565      27.588765    (Mg, Pt)    mp-18707   \n",
       "\n",
       "                                           structure  \\\n",
       "0  [[0. 0. 0.] Al, [0.         1.96140395 1.96140...   \n",
       "1  [[-2.23765223e-08  1.42974191e+00  5.92614104e...   \n",
       "2  [[2.24450185 3.85793022 4.83390736] O, [2.7788...   \n",
       "3  [[0.         1.86144248 1.86144248] Cu, [1.861...   \n",
       "4  [[0.         0.         2.73626461] Mg, [0.   ...   \n",
       "\n",
       "                                        brgoch_feats  suspect_value  \\\n",
       "0  {'atomic_number_feat_1': 123.5, 'atomic_number...          False   \n",
       "1  {'atomic_number_feat_1': 45.5, 'atomic_number_...          False   \n",
       "2  {'atomic_number_feat_1': 44.0, 'atomic_number_...          False   \n",
       "3  {'atomic_number_feat_1': 82.5, 'atomic_number_...          False   \n",
       "4  {'atomic_number_feat_1': 57.0, 'atomic_number_...          False   \n",
       "\n",
       "   Allred-Rochow_EN_feat_1  Allred-Rochow_EN_feat_2  ...  \\\n",
       "0                   3.3865                    3.547  ...   \n",
       "1                   2.4550                    2.090  ...   \n",
       "2                   4.1900                    6.060  ...   \n",
       "3                   3.6350                    3.830  ...   \n",
       "4                   2.7995                    2.159  ...   \n",
       "\n",
       "   specific_heat_feat_1  specific_heat_feat_2  specific_heat_feat_3  \\\n",
       "0                 0.645                  0.51                  0.13   \n",
       "1                 0.610                  0.70                  0.26   \n",
       "2                 0.990                  1.70                  0.14   \n",
       "3                 0.635                  1.01                  0.13   \n",
       "4                 1.595                  2.93                  0.13   \n",
       "\n",
       "   specific_heat_feat_4  thermal_conductivity_feat_1  \\\n",
       "0                  0.90                    225.90000   \n",
       "1                  0.48                     34.67000   \n",
       "2                  0.92                     11.52674   \n",
       "3                  0.38                    637.30000   \n",
       "4                  1.02                    269.80000   \n",
       "\n",
       "   thermal_conductivity_feat_2  thermal_conductivity_feat_3  \\\n",
       "0                     22.20000                     71.60000   \n",
       "1                     38.06000                      7.82000   \n",
       "2                     22.94652                      0.02674   \n",
       "3                   1131.40000                     71.60000   \n",
       "4                    396.40000                     71.60000   \n",
       "\n",
       "   thermal_conductivity_feat_4  valence_electron_density  volume_per_atom  \n",
       "0                        237.0                  0.899196        14.457360  \n",
       "1                         53.7                  0.947211        12.668777  \n",
       "2                         23.0                  0.850563        11.756914  \n",
       "3                        401.0                  1.740288        12.066970  \n",
       "4                        156.0                  0.638524        18.793352  \n",
       "\n",
       "[5 rows x 158 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "716ed5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bulk_modulus</th>\n",
       "      <th>shear_modulus</th>\n",
       "      <th>Allred-Rochow_EN_feat_1</th>\n",
       "      <th>Allred-Rochow_EN_feat_2</th>\n",
       "      <th>Allred-Rochow_EN_feat_3</th>\n",
       "      <th>Allred-Rochow_EN_feat_4</th>\n",
       "      <th>Gillman_number_VE_feat_1</th>\n",
       "      <th>Gillman_number_VE_feat_2</th>\n",
       "      <th>Gillman_number_VE_feat_3</th>\n",
       "      <th>Gillman_number_VE_feat_4</th>\n",
       "      <th>...</th>\n",
       "      <th>specific_heat_feat_1</th>\n",
       "      <th>specific_heat_feat_2</th>\n",
       "      <th>specific_heat_feat_3</th>\n",
       "      <th>specific_heat_feat_4</th>\n",
       "      <th>thermal_conductivity_feat_1</th>\n",
       "      <th>thermal_conductivity_feat_2</th>\n",
       "      <th>thermal_conductivity_feat_3</th>\n",
       "      <th>thermal_conductivity_feat_4</th>\n",
       "      <th>valence_electron_density</th>\n",
       "      <th>volume_per_atom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2574.000000</td>\n",
       "      <td>2574.000000</td>\n",
       "      <td>2574.000000</td>\n",
       "      <td>2574.000000</td>\n",
       "      <td>2574.000000</td>\n",
       "      <td>2574.000000</td>\n",
       "      <td>2574.000000</td>\n",
       "      <td>2574.000000</td>\n",
       "      <td>2574.000000</td>\n",
       "      <td>2574.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2574.000000</td>\n",
       "      <td>2574.000000</td>\n",
       "      <td>2574.000000</td>\n",
       "      <td>2574.000000</td>\n",
       "      <td>2574.000000</td>\n",
       "      <td>2574.000000</td>\n",
       "      <td>2574.000000</td>\n",
       "      <td>2574.000000</td>\n",
       "      <td>2574.000000</td>\n",
       "      <td>2574.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>118.792108</td>\n",
       "      <td>59.811241</td>\n",
       "      <td>3.386460</td>\n",
       "      <td>3.564600</td>\n",
       "      <td>1.332096</td>\n",
       "      <td>2.271378</td>\n",
       "      <td>6.357226</td>\n",
       "      <td>7.321678</td>\n",
       "      <td>2.182595</td>\n",
       "      <td>4.634033</td>\n",
       "      <td>...</td>\n",
       "      <td>1.086355</td>\n",
       "      <td>1.417828</td>\n",
       "      <td>0.276815</td>\n",
       "      <td>0.831197</td>\n",
       "      <td>160.801920</td>\n",
       "      <td>236.990894</td>\n",
       "      <td>29.117198</td>\n",
       "      <td>149.896177</td>\n",
       "      <td>0.874320</td>\n",
       "      <td>17.562392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>71.055862</td>\n",
       "      <td>41.593327</td>\n",
       "      <td>2.371095</td>\n",
       "      <td>4.390938</td>\n",
       "      <td>0.320949</td>\n",
       "      <td>0.669024</td>\n",
       "      <td>4.474709</td>\n",
       "      <td>8.040068</td>\n",
       "      <td>1.037235</td>\n",
       "      <td>1.315585</td>\n",
       "      <td>...</td>\n",
       "      <td>1.771782</td>\n",
       "      <td>3.224834</td>\n",
       "      <td>0.152370</td>\n",
       "      <td>0.705139</td>\n",
       "      <td>238.991066</td>\n",
       "      <td>379.748151</td>\n",
       "      <td>39.690045</td>\n",
       "      <td>107.450922</td>\n",
       "      <td>0.381962</td>\n",
       "      <td>5.879860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.594447</td>\n",
       "      <td>2.457116</td>\n",
       "      <td>1.128000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.659000</td>\n",
       "      <td>1.034000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>1.201740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>2.350000</td>\n",
       "      <td>0.103454</td>\n",
       "      <td>5.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>59.640197</td>\n",
       "      <td>28.239200</td>\n",
       "      <td>1.953125</td>\n",
       "      <td>0.804750</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>1.840000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>54.094917</td>\n",
       "      <td>62.590000</td>\n",
       "      <td>0.269000</td>\n",
       "      <td>71.800000</td>\n",
       "      <td>0.621899</td>\n",
       "      <td>13.505831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>111.810573</td>\n",
       "      <td>51.575971</td>\n",
       "      <td>2.741000</td>\n",
       "      <td>2.197500</td>\n",
       "      <td>1.340000</td>\n",
       "      <td>1.994000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>100.013370</td>\n",
       "      <td>128.200000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>0.842400</td>\n",
       "      <td>16.350172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>167.303237</td>\n",
       "      <td>81.755428</td>\n",
       "      <td>4.010375</td>\n",
       "      <td>4.146000</td>\n",
       "      <td>1.590000</td>\n",
       "      <td>2.544000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.161333</td>\n",
       "      <td>1.460000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>178.679167</td>\n",
       "      <td>253.843530</td>\n",
       "      <td>35.300000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>1.070135</td>\n",
       "      <td>20.634837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>385.194240</td>\n",
       "      <td>383.403010</td>\n",
       "      <td>39.064500</td>\n",
       "      <td>40.584000</td>\n",
       "      <td>2.158000</td>\n",
       "      <td>4.193000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>28.420000</td>\n",
       "      <td>53.488000</td>\n",
       "      <td>1.040000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>5349.000000</td>\n",
       "      <td>4404.200000</td>\n",
       "      <td>317.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>2.659142</td>\n",
       "      <td>48.844971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 152 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bulk_modulus  shear_modulus  Allred-Rochow_EN_feat_1  \\\n",
       "count   2574.000000    2574.000000              2574.000000   \n",
       "mean     118.792108      59.811241                 3.386460   \n",
       "std       71.055862      41.593327                 2.371095   \n",
       "min        3.594447       2.457116                 1.128000   \n",
       "25%       59.640197      28.239200                 1.953125   \n",
       "50%      111.810573      51.575971                 2.741000   \n",
       "75%      167.303237      81.755428                 4.010375   \n",
       "max      385.194240     383.403010                39.064500   \n",
       "\n",
       "       Allred-Rochow_EN_feat_2  Allred-Rochow_EN_feat_3  \\\n",
       "count              2574.000000              2574.000000   \n",
       "mean                  3.564600                 1.332096   \n",
       "std                   4.390938                 0.320949   \n",
       "min                   0.000000                 0.659000   \n",
       "25%                   0.804750                 1.120000   \n",
       "50%                   2.197500                 1.340000   \n",
       "75%                   4.146000                 1.590000   \n",
       "max                  40.584000                 2.158000   \n",
       "\n",
       "       Allred-Rochow_EN_feat_4  Gillman_number_VE_feat_1  \\\n",
       "count              2574.000000               2574.000000   \n",
       "mean                  2.271378                  6.357226   \n",
       "std                   0.669024                  4.474709   \n",
       "min                   1.034000                  1.000000   \n",
       "25%                   1.840000                  3.666667   \n",
       "50%                   1.994000                  5.000000   \n",
       "75%                   2.544000                  7.500000   \n",
       "max                   4.193000                 68.000000   \n",
       "\n",
       "       Gillman_number_VE_feat_2  Gillman_number_VE_feat_3  \\\n",
       "count               2574.000000               2574.000000   \n",
       "mean                   7.321678                  2.182595   \n",
       "std                    8.040068                  1.037235   \n",
       "min                    0.000000                  1.000000   \n",
       "25%                    2.000000                  1.000000   \n",
       "50%                    5.000000                  2.000000   \n",
       "75%                    9.000000                  3.000000   \n",
       "max                   69.000000                  6.000000   \n",
       "\n",
       "       Gillman_number_VE_feat_4  ...  specific_heat_feat_1  \\\n",
       "count               2574.000000  ...           2574.000000   \n",
       "mean                   4.634033  ...              1.086355   \n",
       "std                    1.315585  ...              1.771782   \n",
       "min                    1.000000  ...              0.130000   \n",
       "25%                    4.000000  ...              0.455000   \n",
       "50%                    5.000000  ...              0.716667   \n",
       "75%                    6.000000  ...              1.161333   \n",
       "max                    7.000000  ...             28.420000   \n",
       "\n",
       "       specific_heat_feat_2  specific_heat_feat_3  specific_heat_feat_4  \\\n",
       "count           2574.000000           2574.000000           2574.000000   \n",
       "mean               1.417828              0.276815              0.831197   \n",
       "std                3.224834              0.152370              0.705139   \n",
       "min                0.000000              0.120000              0.130000   \n",
       "25%                0.260000              0.140000              0.440000   \n",
       "50%                0.600000              0.240000              0.710000   \n",
       "75%                1.460000              0.330000              0.920000   \n",
       "max               53.488000              1.040000              3.600000   \n",
       "\n",
       "       thermal_conductivity_feat_1  thermal_conductivity_feat_2  \\\n",
       "count                  2574.000000                  2574.000000   \n",
       "mean                    160.801920                   236.990894   \n",
       "std                     238.991066                   379.748151   \n",
       "min                       1.201740                     0.000000   \n",
       "25%                      54.094917                    62.590000   \n",
       "50%                     100.013370                   128.200000   \n",
       "75%                     178.679167                   253.843530   \n",
       "max                    5349.000000                  4404.200000   \n",
       "\n",
       "       thermal_conductivity_feat_3  thermal_conductivity_feat_4  \\\n",
       "count                  2574.000000                  2574.000000   \n",
       "mean                     29.117198                   149.896177   \n",
       "std                      39.690045                   107.450922   \n",
       "min                       0.008900                     2.350000   \n",
       "25%                       0.269000                    71.800000   \n",
       "50%                      17.200000                   116.000000   \n",
       "75%                      35.300000                   200.000000   \n",
       "max                     317.000000                   429.000000   \n",
       "\n",
       "       valence_electron_density  volume_per_atom  \n",
       "count               2574.000000      2574.000000  \n",
       "mean                   0.874320        17.562392  \n",
       "std                    0.381962         5.879860  \n",
       "min                    0.103454         5.890000  \n",
       "25%                    0.621899        13.505831  \n",
       "50%                    0.842400        16.350172  \n",
       "75%                    1.070135        20.634837  \n",
       "max                    2.659142        48.844971  \n",
       "\n",
       "[8 rows x 152 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1eaf4b",
   "metadata": {},
   "source": [
    "### Separate features from targets and non-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7e56504",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['bulk_modulus', 'shear_modulus']\n",
    "non_features = ['formula', 'composition', 'material_id', 'structure', 'brgoch_feats', 'suspect_value']\n",
    "columns = list(df)\n",
    "features = [f for f in columns if f not in targets if f not in non_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f9da58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Allred-Rochow_EN_feat_1',\n",
       " 'Allred-Rochow_EN_feat_2',\n",
       " 'Allred-Rochow_EN_feat_3',\n",
       " 'Allred-Rochow_EN_feat_4',\n",
       " 'Gillman_number_VE_feat_1',\n",
       " 'Gillman_number_VE_feat_2',\n",
       " 'Gillman_number_VE_feat_3',\n",
       " 'Gillman_number_VE_feat_4',\n",
       " 'Gilman_electron_density',\n",
       " 'Gordy_EN_feat_1',\n",
       " 'Gordy_EN_feat_2',\n",
       " 'Gordy_EN_feat_3',\n",
       " 'Gordy_EN_feat_4',\n",
       " 'Laue_class',\n",
       " 'Martynov_EN_feat_1',\n",
       " 'Martynov_EN_feat_2',\n",
       " 'Martynov_EN_feat_3',\n",
       " 'Martynov_EN_feat_4',\n",
       " 'Mendeleev_number_feat_1',\n",
       " 'Mendeleev_number_feat_2',\n",
       " 'Mendeleev_number_feat_3',\n",
       " 'Mendeleev_number_feat_4',\n",
       " 'Mulliken_EN_feat_1',\n",
       " 'Mulliken_EN_feat_2',\n",
       " 'Mulliken_EN_feat_3',\n",
       " 'Mulliken_EN_feat_4',\n",
       " 'Pauling_EN_feat_1',\n",
       " 'Pauling_EN_feat_2',\n",
       " 'Pauling_EN_feat_3',\n",
       " 'Pauling_EN_feat_4',\n",
       " 'Zungar_radius_feat_1',\n",
       " 'Zungar_radius_feat_2',\n",
       " 'Zungar_radius_feat_3',\n",
       " 'Zungar_radius_feat_4',\n",
       " 'anisotropy',\n",
       " 'atomic_number_feat_1',\n",
       " 'atomic_number_feat_2',\n",
       " 'atomic_number_feat_3',\n",
       " 'atomic_number_feat_4',\n",
       " 'atomic_radius_feat_1',\n",
       " 'atomic_radius_feat_2',\n",
       " 'atomic_radius_feat_3',\n",
       " 'atomic_radius_feat_4',\n",
       " 'atomic_weight_feat_1',\n",
       " 'atomic_weight_feat_2',\n",
       " 'atomic_weight_feat_3',\n",
       " 'atomic_weight_feat_4',\n",
       " 'boiling_point_feat_1',\n",
       " 'boiling_point_feat_2',\n",
       " 'boiling_point_feat_3',\n",
       " 'boiling_point_feat_4',\n",
       " 'cohesive_energy_feat_1',\n",
       " 'cohesive_energy_feat_2',\n",
       " 'cohesive_energy_feat_3',\n",
       " 'cohesive_energy_feat_4',\n",
       " 'covalent_radius_feat_1',\n",
       " 'covalent_radius_feat_2',\n",
       " 'covalent_radius_feat_3',\n",
       " 'covalent_radius_feat_4',\n",
       " 'crystal_class',\n",
       " 'crystal_radius_feat_1',\n",
       " 'crystal_radius_feat_2',\n",
       " 'crystal_radius_feat_3',\n",
       " 'crystal_radius_feat_4',\n",
       " 'crystal_system',\n",
       " 'density',\n",
       " 'density_feat_1',\n",
       " 'density_feat_2',\n",
       " 'density_feat_3',\n",
       " 'density_feat_4',\n",
       " 'electron_density',\n",
       " 'family_number_feat_1',\n",
       " 'family_number_feat_2',\n",
       " 'family_number_feat_3',\n",
       " 'family_number_feat_4',\n",
       " 'first_ionization_energy_feat_1',\n",
       " 'first_ionization_energy_feat_2',\n",
       " 'first_ionization_energy_feat_3',\n",
       " 'first_ionization_energy_feat_4',\n",
       " 'group_number_feat_1',\n",
       " 'group_number_feat_2',\n",
       " 'group_number_feat_3',\n",
       " 'group_number_feat_4',\n",
       " 'heat_of_atomization_feat_1',\n",
       " 'heat_of_atomization_feat_2',\n",
       " 'heat_of_atomization_feat_3',\n",
       " 'heat_of_atomization_feat_4',\n",
       " 'heat_of_fusion_feat_1',\n",
       " 'heat_of_fusion_feat_2',\n",
       " 'heat_of_fusion_feat_3',\n",
       " 'heat_of_fusion_feat_4',\n",
       " 'heat_of_vaporization_feat_1',\n",
       " 'heat_of_vaporization_feat_2',\n",
       " 'heat_of_vaporization_feat_3',\n",
       " 'heat_of_vaporization_feat_4',\n",
       " 'inversion_centre',\n",
       " 'ionic_radius_feat_1',\n",
       " 'ionic_radius_feat_2',\n",
       " 'ionic_radius_feat_3',\n",
       " 'ionic_radius_feat_4',\n",
       " 'melting_point_feat_1',\n",
       " 'melting_point_feat_2',\n",
       " 'melting_point_feat_3',\n",
       " 'melting_point_feat_4',\n",
       " 'metallic_valence_feat_1',\n",
       " 'metallic_valence_feat_2',\n",
       " 'metallic_valence_feat_3',\n",
       " 'metallic_valence_feat_4',\n",
       " 'number_VE_feat_1',\n",
       " 'number_VE_feat_2',\n",
       " 'number_VE_feat_3',\n",
       " 'number_VE_feat_4',\n",
       " 'number_d_electrons_feat_1',\n",
       " 'number_d_electrons_feat_2',\n",
       " 'number_d_electrons_feat_3',\n",
       " 'number_d_electrons_feat_4',\n",
       " 'number_outer_shell_electrons_feat_1',\n",
       " 'number_outer_shell_electrons_feat_2',\n",
       " 'number_outer_shell_electrons_feat_3',\n",
       " 'number_outer_shell_electrons_feat_4',\n",
       " 'number_p_electrons_feat_1',\n",
       " 'number_p_electrons_feat_2',\n",
       " 'number_p_electrons_feat_3',\n",
       " 'number_p_electrons_feat_4',\n",
       " 'number_s_electrons_feat_1',\n",
       " 'number_s_electrons_feat_2',\n",
       " 'number_s_electrons_feat_3',\n",
       " 'number_s_electrons_feat_4',\n",
       " 'outer_shell_electron_density',\n",
       " 'period_number_feat_1',\n",
       " 'period_number_feat_2',\n",
       " 'period_number_feat_3',\n",
       " 'period_number_feat_4',\n",
       " 'polar_axis',\n",
       " 'polarizability_feat_1',\n",
       " 'polarizability_feat_2',\n",
       " 'polarizability_feat_3',\n",
       " 'polarizability_feat_4',\n",
       " 'reduced_volume',\n",
       " 'space_group_number',\n",
       " 'specific_heat_feat_1',\n",
       " 'specific_heat_feat_2',\n",
       " 'specific_heat_feat_3',\n",
       " 'specific_heat_feat_4',\n",
       " 'thermal_conductivity_feat_1',\n",
       " 'thermal_conductivity_feat_2',\n",
       " 'thermal_conductivity_feat_3',\n",
       " 'thermal_conductivity_feat_4',\n",
       " 'valence_electron_density',\n",
       " 'volume_per_atom']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2101313a",
   "metadata": {},
   "source": [
    "## (b) Train a support vector regressor to predict bulk modulus\n",
    "**Guidelines**:\n",
    "1. reserve 15% of your data for testing\n",
    "2. scale your features \n",
    "3. identify the best regularization parameter (`C`) to use with a polynomial kernel\n",
    "4. plot the training and validation RMSE as a function of `C` and breifly discuss why you think the `C` value you chose is best (1-2 sentences)\n",
    "\n",
    "**Scoring**:\n",
    "- +2 points for attempting each point in the guidelines\n",
    "- +3 points for satisfactorily addressing each point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "882ddb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### SOLUTION\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "#plt.style.use('../../modules/files/plot_style.mplstyle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "106e4030",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### SOLUTION\n",
    "\n",
    "X, y = df[features].values, df['bulk_modulus'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=44)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e6adbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### SOLUTION\n",
    "\n",
    "def rmse(actual, pred):\n",
    "    return np.sqrt(np.mean([(actual[i]-pred[i])**2 for i in range(len(actual))]))\n",
    "   \n",
    "def run_cv(n_folds, model, X_train, y_train, stratify=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        n_folds (int) : how many folds of CV to do\n",
    "        model (sklearn Model) : what model do we want to fit\n",
    "        X_train (np.array) : feature matrix\n",
    "        y_train (np.array) : target array\n",
    "        stratify (bool) : if True, use stratified CV, otherwise, use random CV\n",
    "        \n",
    "    Returns:\n",
    "        a dictionary with scores from each fold for training and validation\n",
    "            {'train' : [list of training scores],\n",
    "             'val' : [list of validation scores]}\n",
    "            - the length of each list = n_folds\n",
    "    \"\"\"\n",
    "    if stratify:\n",
    "        folds = StratifiedKFold(n_splits=n_folds).split(X_train, y_train)\n",
    "    else:\n",
    "        folds = KFold(n_splits=n_folds).split(X_train, y_train)\n",
    "\n",
    "    train_scores, val_scores = [], []\n",
    "    for k, (train, val) in enumerate(folds):\n",
    "        \n",
    "        X_train_cv = X_train[train]\n",
    "        y_train_cv = y_train[train]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_cv = scaler.fit_transform(X_train_cv)\n",
    "\n",
    "        X_val_cv = X_train[val]\n",
    "        X_val_cv = scaler.transform(X_val_cv)\n",
    "        y_val_cv = y_train[val]\n",
    "\n",
    "        model.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "        y_train_cv_pred = model.predict(X_train_cv)\n",
    "        y_val_cv_pred = model.predict(X_val_cv)\n",
    "\n",
    "        train_acc = rmse(y_train_cv, y_train_cv_pred)\n",
    "        val_acc = rmse(y_val_cv, y_val_cv_pred)\n",
    "\n",
    "        train_scores.append(train_acc)\n",
    "        val_scores.append(val_acc)\n",
    "\n",
    "    print('%i Folds' % n_folds)\n",
    "    print('Mean training rmse = %.1f +/- %.2f' % (np.mean(train_scores), np.std(train_scores)))\n",
    "    print('Mean validation rmse = %.1f +/- %.2f' % (np.mean(val_scores), np.std(val_scores)))\n",
    "    \n",
    "    return {'train' : train_scores,\n",
    "            'val' : val_scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a77c0db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "~~~ C=1 ~~~ \n",
      "5 Folds\n",
      "Mean training rmse = 56.9 +/- 0.68\n",
      "Mean validation rmse = 60.8 +/- 2.67\n",
      "\n",
      "~~~ C=10 ~~~ \n",
      "5 Folds\n",
      "Mean training rmse = 35.3 +/- 0.44\n",
      "Mean validation rmse = 52.1 +/- 13.53\n",
      "\n",
      "~~~ C=100 ~~~ \n",
      "5 Folds\n",
      "Mean training rmse = 18.2 +/- 0.49\n",
      "Mean validation rmse = 61.5 +/- 34.49\n"
     ]
    }
   ],
   "source": [
    "######### SOLUTION\n",
    "\n",
    "Cs = [1, 10, 100]\n",
    "\n",
    "n_folds = 5\n",
    "\n",
    "scores = {C : {} for C in Cs}\n",
    "for C in Cs:\n",
    "    print('\\n~~~ C=%i ~~~ ' % C)\n",
    "    scores[C] = run_cv(n_folds=n_folds, model=SVR(kernel='poly', C=C), X_train=X_train, y_train=y_train, stratify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cb72357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "~~~ C=1 ~~~ \n",
      "5 Folds\n",
      "Mean training rmse = 56.9 +/- 0.68\n",
      "Mean validation rmse = 60.8 +/- 2.67\n",
      "\n",
      "~~~ C=2 ~~~ \n",
      "5 Folds\n",
      "Mean training rmse = 50.7 +/- 0.59\n",
      "Mean validation rmse = 57.3 +/- 4.10\n",
      "\n",
      "~~~ C=4 ~~~ \n",
      "5 Folds\n",
      "Mean training rmse = 44.1 +/- 0.59\n",
      "Mean validation rmse = 53.9 +/- 7.17\n",
      "\n",
      "~~~ C=8 ~~~ \n",
      "5 Folds\n",
      "Mean training rmse = 37.4 +/- 0.41\n",
      "Mean validation rmse = 52.7 +/- 11.90\n",
      "\n",
      "~~~ C=16 ~~~ \n",
      "5 Folds\n",
      "Mean training rmse = 31.5 +/- 0.41\n",
      "Mean validation rmse = 52.7 +/- 17.28\n",
      "\n",
      "~~~ C=32 ~~~ \n",
      "5 Folds\n",
      "Mean training rmse = 25.7 +/- 0.42\n",
      "Mean validation rmse = 53.2 +/- 21.09\n",
      "\n",
      "~~~ C=64 ~~~ \n",
      "5 Folds\n",
      "Mean training rmse = 20.8 +/- 0.44\n",
      "Mean validation rmse = 56.8 +/- 29.04\n"
     ]
    }
   ],
   "source": [
    "######### SOLUTION\n",
    "\n",
    "Cs = [1, 2, 4, 8, 16, 32, 64]\n",
    "\n",
    "n_folds = 5\n",
    "\n",
    "for C in Cs:\n",
    "    print('\\n~~~ C=%i ~~~ ' % C)\n",
    "    scores[C] = run_cv(n_folds=n_folds, model=SVR(kernel='poly', C=C), X_train=X_train, y_train=y_train, stratify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a1d38f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "######### SOLUTION\n",
    "\n",
    "fig = plt.figure(figsize=(4,2))\n",
    "ax = plt.subplot()\n",
    "\n",
    "x = sorted([C for C in scores])\n",
    "train_means = [np.mean(scores[C]['train']) for C in x]\n",
    "val_means = [np.mean(scores[C]['val']) for C in x]\n",
    "\n",
    "ax = plt.plot(x, train_means, markerfacecolor='white', color='blue', marker='o', label='train')\n",
    "ax = plt.plot(x, val_means, markerfacecolor='white', color='orange', marker='^', label='val')\n",
    "ax = plt.legend(loc='best')\n",
    "ax = plt.xlabel('C')\n",
    "ax = plt.ylabel('RMSE (GPa)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64d004c-6c9e-480e-ade5-756bbc52c37a",
   "metadata": {},
   "source": [
    "### ***SOLUTION***\n",
    "- A regularization parameter of ~4-40 seems reasonable because the validation error is lowest with these C values\n",
    "- I would probably use a value of ~4-10 because these models are less over-fit to the training data (have less variance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf63ae8",
   "metadata": {},
   "source": [
    "### (c) Use permutation importances to determine which features are most important for this prediction\n",
    "\n",
    "**Guidelines**:\n",
    "- use `sklearn.inspection.permutation_importance`\n",
    "- use `SVR(kernel='poly', C=32)` as your estimator\n",
    "- permutation importances should be determined on a validation set\n",
    "    - you should fit your estimator to a subset of `X_train`, `y_train` and determine importances using a different subset\n",
    "- use `n_repeats = 2` so that it doesn't take too long\n",
    "- use `scoring = 'neg_root_mean_squared_error'`\n",
    "- print the 10 most important features\n",
    "    - print the feature name along with the importance value\n",
    "- plot a bar chart of all sorted importances\n",
    "    - the y-axis is the feature importance\n",
    "    - the x-axis is the index of each feature (index = 0 should correspond with the most important feature)\n",
    "\n",
    "**Hints**:\n",
    "- review the [User Guide](https://scikit-learn.org/stable/modules/permutation_importance.html#permutation-importance) for `permutation_importance`\n",
    "\n",
    "**Scoring**:\n",
    "- +4 points for attempting\n",
    "- +3 points for successfully computing permutation importances\n",
    "- +1 point for correctly using a validation set\n",
    "- +1 point for printing the 10 most important features and their corresponding importance values\n",
    "- +1 point for generating the bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4219211",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## SOLUTION\n",
    "\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0603d73e-37d0-4f8f-b45c-15cb67a218ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVR(C=32, kernel=&#x27;poly&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR(C=32, kernel=&#x27;poly&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVR(C=32, kernel='poly')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########## SOLUTION\n",
    "\n",
    "model = SVR(kernel='poly', C=32)\n",
    "X_train_train, X_train_val, y_train_train, y_train_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "model.fit(X_train_train, y_train_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8838ce1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## SOLUTION\n",
    "\n",
    "r = permutation_importance(estimator=model, X=X_train_val, y=y_train_val, n_repeats=2, random_state=44, scoring='neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01dfab6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature No. 0 = boiling_point_feat_1 w/ importance = 82.9\n",
      "Feature No. 1 = heat_of_vaporization_feat_1 w/ importance = 25.9\n",
      "Feature No. 2 = heat_of_atomization_feat_1 w/ importance = 25.9\n",
      "Feature No. 3 = first_ionization_energy_feat_1 w/ importance = 21.8\n",
      "Feature No. 4 = boiling_point_feat_2 w/ importance = 21.3\n",
      "Feature No. 5 = first_ionization_energy_feat_2 w/ importance = 17.2\n",
      "Feature No. 6 = melting_point_feat_1 w/ importance = 6.7\n",
      "Feature No. 7 = boiling_point_feat_4 w/ importance = 3.9\n",
      "Feature No. 8 = boiling_point_feat_3 w/ importance = 3.8\n",
      "Feature No. 9 = heat_of_vaporization_feat_2 w/ importance = 3.4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########## SOLUTION\n",
    "\n",
    "feature_names = []\n",
    "mean_importances = []\n",
    "for i in r.importances_mean.argsort()[::-1]:\n",
    "    feature_names.append(features[i])\n",
    "    mean_importances.append(r.importances_mean[i])\n",
    "    \n",
    "for i in range(10):\n",
    "    print('Feature No. %i = %s w/ importance = %.1f' % (i, feature_names[i], mean_importances[i]))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.bar(range(len(feature_names)), mean_importances)\n",
    "ax = plt.ylabel('importance')\n",
    "ax = plt.xlabel('feature indices (ranked)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25d4c17-0d85-4533-9f48-9c1ec51f607f",
   "metadata": {},
   "source": [
    "### (d) Consider how feature correlations might influence your results\n",
    "**Guidelines**:\n",
    "- compute the pairwise Pearson correlation among three features in your model: `['crystal_radius_feat_1', 'covalent_radius_feat_1', 'ionic_radius_feat_1']`\n",
    "- for the purposes of this exercise, it's OK to use your full data (ie the whole DataFrame). In practice, you'd want to do this only on the training set\n",
    "- your printed output should be:\n",
    "  - PC(feature 1, feature 2) = <the Pearson correlation between feature 1 and feature 2> \n",
    "  - PC(feature 1, feature 3) = <the Pearson correlation between feature 1 and feature 3>\n",
    "  - PC(feature 2, feature 3) = <the Pearson correlation between feature 2 and feature 3>\n",
    "- discuss the implications of these correlations on: 1) training the model and 2) interpreting the feature importances\n",
    "\n",
    "**Hints**:\n",
    "- [this link](https://realpython.com/numpy-scipy-pandas-correlation-python/) may help\n",
    "\n",
    "**Scoring**:\n",
    "- +4 points for attempting\n",
    "- +4 points for correctly computing and printing Pearson correlations\n",
    "- +2 points for discussing implications for training\n",
    "- +2 points for appropriately discussing implications for interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98ac76a1-ba32-4ce4-9ad5-cd18e9b35279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC(crystal_radius_feat_1, covalent_radius_feat_1) = 0.88\n",
      "PC(crystal_radius_feat_1, ionic_radius_feat_1) = 0.86\n",
      "PC(covalent_radius_feat_1, ionic_radius_feat_1) = 1.00\n"
     ]
    }
   ],
   "source": [
    "######## SOLUTION\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "radii_features = ['crystal_radius_feat_1', 'covalent_radius_feat_1', 'ionic_radius_feat_1']\n",
    "\n",
    "corr = df[radii_features].corr(method='pearson')\n",
    "\n",
    "feature1, feature2 = radii_features[0], radii_features[1]\n",
    "print('PC(%s, %s) = %.2f' % (feature1, feature2, pearsonr(df[feature1].values, df[feature2].values).statistic))\n",
    "feature1, feature2 = radii_features[0], radii_features[2]\n",
    "print('PC(%s, %s) = %.2f' % (feature1, feature2, pearsonr(df[feature1].values, df[feature2].values).statistic))\n",
    "feature1, feature2 = radii_features[1], radii_features[2]\n",
    "print('PC(%s, %s) = %.2f' % (feature1, feature2, pearsonr(df[feature1].values, df[feature2].values).statistic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f98c89-1c6e-4339-afee-812490cf3438",
   "metadata": {},
   "source": [
    "### SOLUTION\n",
    "1. These features are highly correlated with one another, which adds unnecessary noise to the model training process. Put another way, nearly all the same information could be supplied with just one of these features, so we are unnecessarily increasing the dimensionality of our model, thereby encouraging overfitting.\n",
    "2. This correlation is especially problematic for interpreting the feature importances. We are trying to understand which features are important to the model. However, because two features carry the same information, the model training process could artificially and randomly distribute \"importance\" between them. This leads to different conclusions than if we were to train a model using just one of these features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsi25_ml-ssc_25.0",
   "language": "python",
   "name": "hsi25_ml-ssc_25.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
